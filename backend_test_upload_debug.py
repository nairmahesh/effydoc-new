import requests
import json
import unittest
import uuid
import os
import time
from datetime import datetime

# Get the backend URL from the frontend .env file
BACKEND_URL = "https://7056c40d-c306-42f0-bfc6-379013315fc8.preview.emergentagent.com/api"

def test_document_upload_debug():
    """Debug the document upload errors and test the complete upload flow"""
    print("Starting document upload debugging tests...")
    
    # Test variables
    base_url = BACKEND_URL
    headers = {"Content-Type": "application/json"}
    test_user_email = f"test.user.{uuid.uuid4()}@example.com"
    test_user_password = "SecurePassword123!"
    
    # 1. Register a test user
    print("\n1. Registering test user...")
    user_data = {
        "email": test_user_email,
        "full_name": "Test User",
        "role": "editor",
        "organization": "Test Organization",
        "password": test_user_password
    }
    
    response = requests.post(f"{base_url}/auth/register", json=user_data)
    assert response.status_code == 200, f"Failed to register test user: {response.text}"
    data = response.json()
    
    # Save token for subsequent tests
    access_token = data["access_token"]
    auth_headers = {"Authorization": f"Bearer {access_token}"}
    print("‚úÖ User registration successful")
    
    # 2. Test with a very large file
    print("\n2. Testing upload with a large file...")
    
    # Create a large text file (5MB)
    large_file_path = "/tmp/large_document.txt"
    with open(large_file_path, "w") as f:
        # Write approximately 5MB of text
        for i in range(5000):
            f.write(f"Line {i}: This is a test line with some content to make the file larger. " * 10)
            f.write("\n")
    
    # Get file size
    file_size = os.path.getsize(large_file_path)
    print(f"Created large file of size: {file_size / (1024 * 1024):.2f} MB")
    
    # Upload the large file
    with open(large_file_path, "rb") as f:
        files = {"file": ("large_document.txt", f, "text/plain")}
        response = requests.post(
            f"{base_url}/documents/upload",
            files=files,
            headers=auth_headers
        )
    
    if response.status_code == 200:
        data = response.json()
        large_document_id = data["document"]["id"]
        print(f"Large file uploaded successfully with ID: {large_document_id}")
        print("‚úÖ Large file upload working")
    else:
        print(f"‚ùå Large file upload failed with status code {response.status_code}")
        print(f"Error: {response.text}")
        large_document_id = None
    
    # 3. Test with a very small file
    print("\n3. Testing upload with a small file...")
    
    # Create a small text file
    small_file_path = "/tmp/small_document.txt"
    with open(small_file_path, "w") as f:
        f.write("This is a very small test document.")
    
    # Upload the small file
    with open(small_file_path, "rb") as f:
        files = {"file": ("small_document.txt", f, "text/plain")}
        response = requests.post(
            f"{base_url}/documents/upload",
            files=files,
            headers=auth_headers
        )
    
    assert response.status_code == 200, f"Failed to upload small file: {response.text}"
    data = response.json()
    small_document_id = data["document"]["id"]
    print(f"Small file uploaded successfully with ID: {small_document_id}")
    print("‚úÖ Small file upload working")
    
    # 4. Test with a file containing special characters
    print("\n4. Testing upload with special characters...")
    
    # Create a file with special characters
    special_file_path = "/tmp/special_document.txt"
    with open(special_file_path, "w") as f:
        f.write("This document contains special characters: !@#$%^&*()_+{}|:<>?~`-=[]\\;',./\n")
        f.write("It also contains unicode characters: √±√°√©√≠√≥√∫√ë√Å√â√ç√ì√ö¬ø¬°‚Ç¨¬£¬•¬©¬Æ‚Ñ¢\n")
        f.write("And emojis: üòÄüöÄüåüüéâüî•üíØ")
    
    # Upload the file with special characters
    with open(special_file_path, "rb") as f:
        files = {"file": ("special_document.txt", f, "text/plain")}
        response = requests.post(
            f"{base_url}/documents/upload",
            files=files,
            headers=auth_headers
        )
    
    assert response.status_code == 200, f"Failed to upload file with special characters: {response.text}"
    data = response.json()
    special_document_id = data["document"]["id"]
    print(f"File with special characters uploaded successfully with ID: {special_document_id}")
    print("‚úÖ File with special characters upload working")
    
    # 5. Test with extract_text parameter explicitly set to True
    print("\n5. Testing upload with extract_text=True explicitly set...")
    
    # Create a test file
    extract_file_path = "/tmp/extract_document.txt"
    with open(extract_file_path, "w") as f:
        f.write("This is a test document for extract_text=True testing.")
    
    # Upload with extract_text=True
    with open(extract_file_path, "rb") as f:
        files = {"file": ("extract_document.txt", f, "text/plain")}
        response = requests.post(
            f"{base_url}/documents/upload",
            files=files,
            data={"extract_text": "true"},
            headers=auth_headers
        )
    
    assert response.status_code == 200, f"Failed to upload with extract_text=True: {response.text}"
    data = response.json()
    extract_document_id = data["document"]["id"]
    print(f"File uploaded with extract_text=True successfully with ID: {extract_document_id}")
    print("‚úÖ Upload with extract_text=True working")
    
    # 6. Test with extract_text parameter set to False
    print("\n6. Testing upload with extract_text=False...")
    
    # Create a test file
    no_extract_file_path = "/tmp/no_extract_document.txt"
    with open(no_extract_file_path, "w") as f:
        f.write("This is a test document for extract_text=False testing.")
    
    # Upload with extract_text=False
    with open(no_extract_file_path, "rb") as f:
        files = {"file": ("no_extract_document.txt", f, "text/plain")}
        response = requests.post(
            f"{base_url}/documents/upload",
            files=files,
            data={"extract_text": "false"},
            headers=auth_headers
        )
    
    assert response.status_code == 200, f"Failed to upload with extract_text=False: {response.text}"
    data = response.json()
    no_extract_document_id = data["document"]["id"]
    print(f"File uploaded with extract_text=False successfully with ID: {no_extract_document_id}")
    print("‚úÖ Upload with extract_text=False working")
    
    # 7. Test the complete upload flow - create a document and then upload content
    print("\n7. Testing complete upload flow...")
    
    # First, create an empty document
    document_data = {
        "title": "Test Flow Document",
        "type": "proposal",
        "organization": "Test Organization",
        "sections": [],
        "collaborators": [],
        "tags": ["test", "flow"],
        "metadata": {"purpose": "testing"}
    }
    
    response = requests.post(f"{base_url}/documents", json=document_data, headers=auth_headers)
    assert response.status_code == 200, f"Failed to create empty document: {response.text}"
    data = response.json()
    flow_document_id = data["id"]
    print(f"Empty document created with ID: {flow_document_id}")
    
    # Now, retrieve the document to verify it was created
    response = requests.get(f"{base_url}/documents/{flow_document_id}", headers=auth_headers)
    assert response.status_code == 200, f"Failed to retrieve empty document: {response.text}"
    data = response.json()
    assert data["id"] == flow_document_id, "Document ID mismatch"
    assert data["title"] == "Test Flow Document", "Document title mismatch"
    
    # Update the document with content
    update_data = {
        "sections": [
            {
                "title": "Introduction",
                "content": "This is the introduction section.",
                "order": 1
            },
            {
                "title": "Details",
                "content": "This is the details section.",
                "order": 2
            }
        ]
    }
    
    response = requests.put(f"{base_url}/documents/{flow_document_id}", json=update_data, headers=auth_headers)
    assert response.status_code == 200, f"Failed to update document with content: {response.text}"
    data = response.json()
    assert len(data["sections"]) == 2, f"Expected 2 sections, got {len(data['sections'])}"
    
    print("‚úÖ Complete document flow working")
    
    # 8. Test concurrent uploads
    print("\n8. Testing concurrent uploads...")
    
    # Create test files
    concurrent_file_paths = []
    for i in range(3):
        file_path = f"/tmp/concurrent_document_{i}.txt"
        with open(file_path, "w") as f:
            f.write(f"This is concurrent test document {i}.")
        concurrent_file_paths.append(file_path)
    
    # Upload files concurrently
    import threading
    
    def upload_file(file_path, index):
        with open(file_path, "rb") as f:
            files = {"file": (f"concurrent_document_{index}.txt", f, "text/plain")}
            response = requests.post(
                f"{base_url}/documents/upload",
                files=files,
                headers=auth_headers
            )
            return response
    
    threads = []
    responses = [None] * len(concurrent_file_paths)
    
    for i, file_path in enumerate(concurrent_file_paths):
        thread = threading.Thread(target=lambda idx=i, path=file_path: responses.__setitem__(idx, upload_file(path, idx)))
        threads.append(thread)
        thread.start()
    
    for thread in threads:
        thread.join()
    
    # Check results
    success_count = 0
    for i, response in enumerate(responses):
        if response and response.status_code == 200:
            success_count += 1
            data = response.json()
            print(f"Concurrent file {i} uploaded successfully with ID: {data['document']['id']}")
    
    print(f"Successfully uploaded {success_count} out of {len(concurrent_file_paths)} concurrent files")
    print("‚úÖ Concurrent uploads working" if success_count == len(concurrent_file_paths) else "‚ö†Ô∏è Some concurrent uploads failed")
    
    # 9. Test upload with missing file
    print("\n9. Testing upload with missing file...")
    
    response = requests.post(
        f"{base_url}/documents/upload",
        files={},
        headers=auth_headers
    )
    
    assert response.status_code != 200, f"Expected error for missing file, got {response.status_code}"
    print("‚úÖ Upload with missing file properly rejected")
    
    # 10. Test upload with empty file
    print("\n10. Testing upload with empty file...")
    
    empty_file_path = "/tmp/empty_document.txt"
    with open(empty_file_path, "w") as f:
        pass  # Create empty file
    
    with open(empty_file_path, "rb") as f:
        files = {"file": ("empty_document.txt", f, "text/plain")}
        response = requests.post(
            f"{base_url}/documents/upload",
            files=files,
            headers=auth_headers
        )
    
    if response.status_code == 200:
        data = response.json()
        empty_document_id = data["document"]["id"]
        print(f"Empty file uploaded successfully with ID: {empty_document_id}")
        print("‚úÖ Empty file upload working")
    else:
        print(f"‚ùå Empty file upload failed with status code {response.status_code}")
        print(f"Error: {response.text}")
        empty_document_id = None
    
    # 11. Clean up
    print("\n11. Cleaning up test documents...")
    
    # Delete all test documents
    document_ids = [
        small_document_id,
        special_document_id,
        extract_document_id,
        no_extract_document_id,
        flow_document_id
    ]
    
    if large_document_id:
        document_ids.append(large_document_id)
    
    if empty_document_id:
        document_ids.append(empty_document_id)
    
    for doc_id in document_ids:
        if doc_id:
            response = requests.delete(f"{base_url}/documents/{doc_id}", headers=auth_headers)
            if response.status_code == 200:
                print(f"Document {doc_id} deleted successfully")
            else:
                print(f"Failed to delete document {doc_id}: {response.status_code}")
    
    # Clean up test files
    test_files = [
        large_file_path,
        small_file_path,
        special_file_path,
        extract_file_path,
        no_extract_file_path,
        empty_file_path
    ] + concurrent_file_paths
    
    for file_path in test_files:
        if os.path.exists(file_path):
            os.remove(file_path)
    
    print("‚úÖ Test cleanup successful")
    
    print("\n‚úÖ All document upload debugging tests completed!")
    print("\nSummary of findings:")
    print("1. Basic document upload functionality is working correctly")
    print("2. The extract_text parameter is properly handled")
    print("3. Special characters in documents are processed correctly")
    print("4. The complete document flow (create -> update -> retrieve) works")
    print("5. Concurrent uploads are handled properly")
    print("6. Error handling for missing files is working")
    print("7. Empty files can be uploaded and processed")
    if large_document_id:
        print("8. Large files (5MB) can be uploaded successfully")
    else:
        print("8. Large files (5MB) upload failed - potential issue with file size limits")

if __name__ == "__main__":
    test_document_upload_debug()